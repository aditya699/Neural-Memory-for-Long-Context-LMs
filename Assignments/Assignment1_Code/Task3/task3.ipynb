{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2e8141",
   "metadata": {},
   "source": [
    "# NOTE: We will revise pytorch and implement a language model from scratch hopefully this will clear all doubts for future weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47786215",
   "metadata": {},
   "source": [
    "# Pytorch Basic Session :1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef10f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 : Understanding nn.Module\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  #By calling super().__init__(), you're saying: \"Hey parent class, set up all your infrastructure before I add my custom stuff.\"(parent class's constructor.))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7af540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([1., 2., 3.])\n",
      "Output: tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "#Setp 1:1 Example\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x * 2\n",
    "\n",
    "# Create model\n",
    "model = SimpleModule()\n",
    "\n",
    "# Test it\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "output = model(x)  # This calls forward() automatically\n",
    "\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6197a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([1., 2., 3.])\n",
      "Weight: Parameter containing:\n",
      "tensor([-1.1037,  0.4698, -0.1627], requires_grad=True)\n",
      "Output: tensor([-1.1037,  0.9396, -0.4880], grad_fn=<MulBackward0>)\n",
      "\n",
      "Is weight learnable? True\n"
     ]
    }
   ],
   "source": [
    "#Step 2 :Understanding nn.Parameter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ModuleWithWeight(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This creates a LEARNABLE parameter\n",
    "        self.weight = nn.Parameter(torch.randn(size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x * self.weight\n",
    "\n",
    "# Create model\n",
    "model = ModuleWithWeight(3)\n",
    "\n",
    "# Test\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "output = model(x)\n",
    "\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"Weight: {model.weight}\")\n",
    "print(f\"Output: {output}\")\n",
    "print(f\"\\nIs weight learnable? {model.weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83ec1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight shape: torch.Size([256, 512])\n",
      "Bias shape: torch.Size([256])\n",
      "Weight requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "# Step 3 : Understanding nn.Linear\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create a linear layer\n",
    "input_dim = 512\n",
    "output_dim = 256\n",
    "linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "# What does it contain?\n",
    "print(f\"Weight shape: {linear.weight.shape}\")\n",
    "print(f\"Bias shape: {linear.bias.shape}\")\n",
    "print(f\"Weight requires_grad: {linear.weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbf1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([32, 10, 512])\n",
      "Output shape: torch.Size([32, 10, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create linear layer\n",
    "linear = nn.Linear(512, 256)\n",
    "# This creates a weight matrix of 256 and 512\n",
    "\n",
    "# Create input\n",
    "batch_size = 32\n",
    "seq_len = 10\n",
    "x = torch.randn(batch_size, seq_len, 512)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(x)\n",
    "\n",
    "print(f\"Input shape:  {x.shape}\")      # [32, 10, 512]\n",
    "print(f\"Output shape: {output.shape}\")  # [32, 10, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f85e53",
   "metadata": {},
   "source": [
    "# Buliding Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffa16e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token IDs shape: torch.Size([2, 10])\n",
      "Output embeddings shape: torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#Start by inheriting from nn.Module\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__() #Call the parent class's constructor so that all methods of nn.Module are properly initialized.\n",
    "        #nn.embedding creates a lookup table that maps from integer indices (representing tokens) to dense vectors of fixed size (the embeddings).\n",
    "        #nn.embedding ,creates a lookup table and intializes it with random values. and makes the values learnable parameters of the model. (also registers it as a parameter of the module)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "    \n",
    "#Create\n",
    "vocab_size = 1000  # Size of the vocabulary\n",
    "d_model = 512    # Dimension of the embeddings\n",
    "token_embed= TokenEmbedding(vocab_size, d_model)\n",
    "\n",
    "#Test\n",
    "token_ids=torch.randint(0, vocab_size, (2,10))\n",
    "output= token_embed (token_ids)\n",
    "print(f\"Input token IDs shape: {token_ids.shape}\")  # [2, 10]\n",
    "print(f\"Output embeddings shape: {output.shape}\")    # [2, 10,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6049e",
   "metadata": {},
   "source": [
    "# Position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69259fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output position embeddings shape: torch.Size([10, 512])\n",
      "Positions Used: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionEmbedding(nn.Module): #Inherit from nn.Module\n",
    "    def __init__(self, max_seq_len, d_model):\n",
    "        super().__init__() #Call the parent class's constructor to make sure all methods of nn.Module are properly initialized. and available.\n",
    "        #NOTE:Transformers (Original paper) used sinusoidal position embeddings, but nn.Embedding is a common choice for learnable position embeddings.(we will make sure gradients also flow through these embeddings during training.)\n",
    "        #This creates a learnable position embedding table of size (max_seq_len, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "    def forward(self, seq_len):\n",
    "        #Generate position indices from 0 to seq_len - 1\n",
    "        positions=torch.arange(seq_len)#This creaates a tensor with seqential numbersye\n",
    "        return self.position_embedding(positions)\n",
    "    \n",
    "#Create\n",
    "pos_embed= PositionEmbedding(max_seq_len=2048, d_model=512)\n",
    "        \n",
    "output = pos_embed(10)  # Example input sequence length\n",
    "print(f\"Output position embeddings shape: {output.shape}\")  # [10, 512]\n",
    "print(f\"Positions Used: {torch.arange(10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e3ce3",
   "metadata": {},
   "source": [
    "# Combine Token and Position Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10])\n",
      "Output shape: torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Embeddings(nn.Module):#This is normal inheritance from nn.Module\n",
    "    def __init__(self, vocab_size, max_seq_len, d_model):\n",
    "        super().__init__() #Initialize the parent class nn.Module so that all its methods and attributes are available. and usable.\n",
    "        \"\"\"\n",
    "        1.token embedding layer to convert token IDs into dense vectors.\n",
    "        2.position embedding layer to add positional information to the token embeddings.\n",
    "\n",
    "        NOTE:Both embeddings are learnable parameters of the model.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_seq_len, d_model)\n",
    "        \n",
    "    def forward(self, token_ids):\n",
    "        batch_size, seq_len = token_ids.shape\n",
    "        \n",
    "        tokens = self.token_embed(token_ids)\n",
    "        #torch.arrange helps to convert tokens into id's which can be used to get position embeddings from nn.Embedding lookup table.\n",
    "        positions = torch.arange(seq_len, device=token_ids.device)\n",
    "        pos = self.pos_embed(positions)\n",
    "        \n",
    "        return tokens + pos\n",
    "\n",
    "# Test\n",
    "embeddings = Embeddings(vocab_size=1000, max_seq_len=2048, d_model=512)\n",
    "token_ids = torch.randint(0, 1000, (2, 10))  # [2, 10]\n",
    "output = embeddings(token_ids)\n",
    "\n",
    "print(f\"Input shape: {token_ids.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
